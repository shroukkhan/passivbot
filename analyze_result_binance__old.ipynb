{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## delete the folders not in live config ( extra crap )\n",
    "live_config_files = glob.glob('cfgs_live/*', recursive=True)\n",
    "allowed_symbols = []\n",
    "symbol_files = {}\n",
    "for f in live_config_files:\n",
    "    symbol = f.split('\\\\')[-1]\n",
    "    symbol = symbol.replace('.json', 'USDT')\n",
    "    allowed_symbols.append(symbol)\n",
    "    symbol_files[symbol] = f\n",
    "\n",
    "# static_configs = {}\n",
    "# for symbol in symbol_files:\n",
    "#     file = symbol_files[symbol]\n",
    "#     with open(file) as f:\n",
    "#         data = json.load(f)\n",
    "#     config_name = data['config_name']\n",
    "#\n",
    "#     if 'static' in config_name:\n",
    "#         t = os.path.getmtime(file)\n",
    "#         modification_time = datetime.datetime.fromtimestamp(t)\n",
    "#         static_configs[symbol] = modification_time\n",
    "#\n",
    "# #print (static_configs)\n",
    "# old_configs_if_before = datetime.datetime(2022, 3, 31)\n",
    "# static_configs_new = [x for x in static_configs if static_configs[x] < old_configs_if_before]\n",
    "#\n",
    "# #print(static_configs_new)\n",
    "# x = ''\n",
    "# for c in static_configs_new:\n",
    "#     x += c+'\\n'\n",
    "# with open('next_batch_config','w') as f:\n",
    "#     f.write(x)\n",
    "#\n",
    "# #allowed_symbols = [\"ALICEUSDT\",\"XRPUSDT\",\"HOTUSDT\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ## NOW copy result folders :)\n",
    "# import json\n",
    "# import shutil\n",
    "#\n",
    "# files = glob.iglob('backtests/binance/' + '**/live_config.json', recursive=True)\n",
    "#\n",
    "# for filename in files:\n",
    "#     with open(filename) as f:\n",
    "#         config = json.load(f)\n",
    "#     symbol = config['config_name'].split('_')[2]\n",
    "#\n",
    "#     if symbol not in symbol_files: continue\n",
    "#\n",
    "#     with open(symbol_files[symbol]) as f:\n",
    "#         production_config = json.load(f)\n",
    "#\n",
    "#     long_pc = production_config['long']\n",
    "#     long_c = config['long']\n",
    "#\n",
    "#     k_pc = long_pc.keys()\n",
    "#     k_c = long_c.keys()\n",
    "#\n",
    "#     if len(k_c) != len(k_c): continue\n",
    "#\n",
    "#     same = True\n",
    "#     for k in k_pc:\n",
    "#         if k not in k_c:\n",
    "#             same = False\n",
    "#             break\n",
    "#         v_pc = long_pc[k]\n",
    "#         v_c = long_c[k]\n",
    "#         #print(f'{k}={v_c},{v_pc}')\n",
    "#\n",
    "#     if not same: continue\n",
    "#\n",
    "#     print(f'{filename} is same as {symbol_files[symbol]}')\n",
    "#\n",
    "#     src = filename.replace('\\\\live_config.json', '')\n",
    "#     dst = f'backtests/binance_production/{symbol}'\n",
    "#     shutil.copytree(src=src, dst=dst, dirs_exist_ok=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "prices_url = \"https://fapi.binance.com/fapi/v1/ticker/price\"\n",
    "pricedata = requests.get(prices_url).json()\n",
    "volume_url = \"https://fapi.binance.com//fapi/v1/ticker/24hr\"\n",
    "volume_data = requests.get(volume_url).json()\n",
    "data_url = \"https://fapi.binance.com/fapi/v1/exchangeInfo\"\n",
    "data = requests.get(data_url).json()\n",
    "\n",
    "symbol_notional_volume = {}\n",
    "\n",
    "for datas in data[\"symbols\"]:\n",
    "    if \"USDT\" in datas[\"pair\"]:\n",
    "        ts = datas['onboardDate']\n",
    "        listed_on = datetime.datetime.utcfromtimestamp(ts / 1000).strftime(\n",
    "            '%Y-%m-%d %H:%M:%S')\n",
    "        symbol = datas[\"pair\"]\n",
    "\n",
    "        if symbol not in allowed_symbols:\n",
    "            continue\n",
    "\n",
    "        min_qty = float(datas[\"filters\"][1][\"minQty\"])\n",
    "        min_notional_fixed = float(datas[\"filters\"][5][\"notional\"])\n",
    "\n",
    "        price = 0\n",
    "        for i in pricedata:\n",
    "            if i[\"symbol\"] == symbol:\n",
    "                price = i[\"price\"]\n",
    "\n",
    "        for i in volume_data:\n",
    "            if i[\"symbol\"] == symbol:\n",
    "                volm = str((int(float(i[\"quoteVolume\"]) / 1000000))).zfill(4)\n",
    "\n",
    "        min_notional_calc = min_qty * float(price)\n",
    "\n",
    "        if min_notional_calc <= min_notional_fixed:\n",
    "            min_notional = min_notional_fixed\n",
    "        else:\n",
    "            min_notional = min_notional_calc\n",
    "\n",
    "        symbol_notional_volume[symbol] = {\n",
    "            \"vol\":volm,\n",
    "            \"listed\":listed_on,\n",
    "            \"notion\":min_notional\n",
    "        }\n",
    "\n",
    "symbol_notional_volume\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## get current config\n",
    "current_config = pd.read_csv('run_config.csv')\n",
    "\n",
    "config_data = {}\n",
    "for symbol in allowed_symbols:\n",
    "    c = current_config.loc[current_config['symbol'] == symbol.replace('USDT','')]\n",
    "    config_data[symbol]={\n",
    "        'lm':c['long_mode'].values[0],\n",
    "        'sm':c['short_mode'].values[0],\n",
    "        'le':c['long_exposure'].values[0],\n",
    "        'se':c['short_exposure'].values[0],\n",
    "    }\n",
    "config_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "big_data = pd.DataFrame()\n",
    "files = glob.iglob('backtests/binance_production/' + '**/backtest_result.txt', recursive=True)\n",
    "i = 0\n",
    "#print(symbol_notional_volume)\n",
    "for filename in files:\n",
    "    #print(f'parsing : {filename}')\n",
    "    with open(filename, 'r') as file:\n",
    "        data = file.read().split('\\n')\n",
    "        d = {'file': filename.replace('backtests/binance_production', '')}\n",
    "        current_state = 'long'\n",
    "        for l in data:\n",
    "            l = l.split('|')\n",
    "            if len(l) == 4:\n",
    "                key = l[1].strip()\n",
    "                value = l[2].strip()\n",
    "\n",
    "                if key == 'Passivbot Version':\n",
    "                    d['v'] = value\n",
    "                if key == 'Symbol':\n",
    "                    d['s'] = value\n",
    "                if key == 'Production Config':\n",
    "                    d['prod'] = value\n",
    "\n",
    "                if key == 'Long':\n",
    "                    current_state = 'long'\n",
    "                    d['long'] = bool(value) or False\n",
    "                if key == 'Short':\n",
    "                    current_state = 'short'\n",
    "                    d['short'] = bool(value) or False\n",
    "\n",
    "                if key == 'Total gain' and current_state == 'long':\n",
    "                    d['tgl_%'] = float(value.replace('%', '').strip())\n",
    "                if key == 'Average daily gain' and current_state == 'long':\n",
    "                    d['adgl_%'] = float(value.replace('%', '').strip())\n",
    "                if key == 'Closest bankruptcy' and current_state == 'long':\n",
    "                    d['bnkrl_%'] = float(value.replace('%', '').strip())\n",
    "                if key == 'Lowest equity/balance ratio' and current_state == 'long':\n",
    "                    d['ebrl'] = float(value.replace('%', '').strip())\n",
    "                if key == 'Max hours stuck' and current_state == 'long':\n",
    "                    d['maxsl'] = float(value.replace('%', '').strip()) / 24\n",
    "                if key == 'Price action distance max' and current_state == 'long':\n",
    "                    d['pamaxl'] = float(value.replace('%', '').strip())\n",
    "                if key == 'Price action distance std' and current_state == 'long':\n",
    "                    d['pastdl'] = float(value.strip())\n",
    "\n",
    "                if key == 'Total gain' and current_state == 'short':\n",
    "                    d['tgs_%'] = float(value.replace('%', '').strip())\n",
    "                if key == 'Average daily gain' and current_state == 'short':\n",
    "                    d['adgs_%'] = float(value.replace('%', '').strip())\n",
    "                if key == 'Closest bankruptcy' and current_state == 'short':\n",
    "                    d['bnkrs_%'] = float(value.replace('%', '').strip())\n",
    "                if key == 'Lowest equity/balance ratio' and current_state == 'short':\n",
    "                    d['ebrs'] = float(value.replace('%', '').strip())\n",
    "                if key == 'Max hours stuck' and current_state == 'short':\n",
    "                    d['maxss'] = float(value.replace('%', '').strip()) / 24\n",
    "                if key == 'Price action distance max' and current_state == 'short':\n",
    "                    d['pamaxs'] = float(value.replace('%', '').strip())\n",
    "                if key == 'Price action distance std' and current_state == 'short':\n",
    "                    d['pastds'] = float(value.strip())\n",
    "\n",
    "        # # symbol_notional_volume[symbol] = {\n",
    "        # #     \"vol\":volm,\n",
    "        # #     \"listed\":listed_on,\n",
    "        # #     \"notion\":min_notional\n",
    "        # # }\n",
    "        symbol = d['s']\n",
    "        d['vol'] = symbol_notional_volume[symbol]['vol']\n",
    "        d['listed'] = symbol_notional_volume[symbol]['listed']\n",
    "        d['notion'] = symbol_notional_volume[symbol]['notion']\n",
    "        # # config_data[symbol]={\n",
    "        # #     'lm':c['long_mode'].values[0],\n",
    "        # #     'sm':c['short_mode'].values[0],\n",
    "        # #     'le':c['long_exposure'].values[0],\n",
    "        # #     'se':c['short_exposure'].values[0],\n",
    "        # # }\n",
    "        d['lm'] = config_data[symbol]['lm']\n",
    "        d['sm'] = config_data[symbol]['sm']\n",
    "        d['le'] = config_data[symbol]['le']\n",
    "        d['se'] = config_data[symbol]['se']\n",
    "        # print(d)\n",
    "        big_data = big_data.append(d, ignore_index=True)\n",
    "\n",
    "big_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filter the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#big_data['adgt_%'] = big_data['adgl_%'] + big_data['adgs_%'] if\n",
    "df = big_data[(big_data.s.isin(allowed_symbols)) ]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop_duplicates(\n",
    "#     subset=['s', 'prod', 'tgl_%', 'tgs_%', 'adgl_%', 'adgs_%', 'adgt_%', 'bnkrl_%', 'bnkrs_%', 'ebrl', 'ebrs', 'long',\n",
    "#             'short'], keep='first',\n",
    "#     inplace=True)\n",
    "dx = df[['s','lm','sm','notion','le','se','vol', 'adgl_%', 'adgs_%', 'bnkrl_%', 'bnkrs_%', 'ebrl', 'ebrs', 'maxsl', 'pamaxl','pastdl',\n",
    "         'maxss', 'pamaxs','pastds' ]]\n",
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds = dx[(dx['sm'] == 'n') | (dx['sm'] == 'gs')]\n",
    "ds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds_proposed = dx[\n",
    "    #(dx['sm'] == 'n') &\n",
    "    (dx['bnkrs_%'] == 100) &\n",
    "    # (dx['ebrs'] > 0.7) &\n",
    "    (dx['pastds'] < 0.1)\n",
    "    #(dx['maxss'] < 35)\n",
    "    ]\n",
    "ds_proposed = ds_proposed[['s','sm','notion','le','se','vol', 'adgs_%', 'bnkrs_%',  'ebrs','maxss', 'pamaxs','pastds' ]]\n",
    "ds_proposed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ds = dx[\n",
    "   (dx['adgs_%'] > 0.00)\n",
    "  #& (dx['bnkrs_%'] == 100.00)\n",
    "]\n",
    "ds = ds[['file', 'prod', 's', 'adgs_%', 'bnkrs_%','ebrs','maxss', 'pamaxs','pastds' ]]\n",
    "ds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "short_symbols = ds['s'].tolist()\n",
    "print(short_symbols)\n",
    "config = pd.read_csv('run_config.csv')\n",
    "config['usdt'] = config['symbol']+'USDT'\n",
    "config = config[(config.usdt.isin(short_symbols))]\n",
    "config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## find the ones that are not supposed to be shorted!\n",
    "short_symbols = ds['s'].tolist()\n",
    "\n",
    "config = pd.read_csv('run_config.csv')\n",
    "config['usdt'] = config['symbol']+'USDT'\n",
    "config = config[(~config.usdt.isin(short_symbols)) & (config['short_mode'] == 'n')]\n",
    "## find the risky ones!\n",
    "not_supposed_to_be_shorted = config['usdt'].tolist()\n",
    "not_supposed_to_be_shorted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dx\n",
    "# ss = dx['s'].tolist()\n",
    "# ss\n",
    "ds_not_good = dx[(dx.s.isin(not_supposed_to_be_shorted))]\n",
    "#s_not_good\n",
    "#ds_not_good\n",
    "ds_not_good"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (passivbot)",
   "language": "python",
   "name": "pycharm-997905a8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
